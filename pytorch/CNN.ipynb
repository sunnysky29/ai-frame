{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN 特点：\n",
    "1） 局部连接\n",
    "2） 权值共享"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### conv2d\n",
    "\n",
    "in_channels (int) – Number of channels in the input image\n",
    "\n",
    "out_channels (int) – Number of channels produced by the convolution\n",
    "\n",
    "kernel_size (int or tuple) – Size of the convolving kernel\n",
    "\n",
    "stride (int or tuple, optional) – Stride of the convolution. Default: 1\n",
    "\n",
    "<img src=\"https://tva1.sinaimg.cn/large/e6c9d24egy1h56ly3galkj20k20d8aaw.jpg\" alt=\"image-20220814211842307\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel.weight:\n",
      " Parameter containing:\n",
      "tensor([[[[-0.2114,  0.0801, -0.2520],\n",
      "          [-0.2688, -0.0469,  0.3085],\n",
      "          [ 0.0192,  0.1497, -0.1336]]]], requires_grad=True)\n",
      " kernel.bias:\n",
      " Parameter containing:\n",
      "tensor([-0.1365], requires_grad=True)\n",
      "------------------------------------------------------------\n",
      "自定义新的权重值\n",
      "kernel.weight:\n",
      " Parameter containing:\n",
      "tensor([[[[-0.2114,  0.0801, -0.2520],\n",
      "          [-0.2688, -0.0469,  0.3085],\n",
      "          [ 0.0192,  0.1497, -0.1336]]]], requires_grad=True)\n",
      " kernel.bias:\n",
      " Parameter containing:\n",
      "tensor([1.], requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 1, 1, 2]),\n",
       " tensor([[[[1.1120, 0.5747]]],\n",
       " \n",
       " \n",
       "         [[[1.0208, 1.2100]]]], grad_fn=<MkldnnConvolutionBackward>))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "kernel = nn.Conv2d(1, 1, 3)  # kernel_size=3\n",
    "print(f'kernel.weight:\\n {kernel.weight}\\n \\\n",
    "kernel.bias:\\n {kernel.bias}')\n",
    "print(f'---'*20)\n",
    "print(f'自定义新的权重值')\n",
    "new_bias = torch.tensor([1.0])\n",
    "kernel.bias=torch.nn.Parameter(new_bias) # 把Tensor的值作为权值赋值给Conv层，这里需要先转为torch.nn.Parameter类型，否则将报错\n",
    "print(f'kernel.weight:\\n {kernel.weight}\\n \\\n",
    "kernel.bias:\\n {kernel.bias}')\n",
    "input = torch.randn(2, 1, 3, 4) # (batch, channel, h,w)\n",
    "out = kernel(input)\n",
    "out.shape, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1, 3, 3]),\n",
       " tensor([[[[12., 12., 17.],\n",
       "           [10., 17., 19.],\n",
       "           [ 9.,  6., 14.]]]], grad_fn=<ThnnConv2DBackward>))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "一个卷积 demo， 来自百面深度学习p6\n",
    "\"\"\"\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "kernel = nn.Conv2d(1, 1, 3)  # kernel_size=3\n",
    "new_bias = torch.tensor([0.0])\n",
    "new_weight = torch.tensor([[[[ 0.0,  1,  2],\n",
    "          [ 2,  2, 0],\n",
    "          [0, 1,  2]]]])\n",
    "kernel.bias=torch.nn.Parameter(new_bias)\n",
    "kernel.weight=torch.nn.Parameter(new_weight)\n",
    "\n",
    "input = torch.tensor([[[[3,3,2,1,0.0],\n",
    "                       [0,0,1,3,1],\n",
    "                        [3,1,2,2,3],\n",
    "                        [2,0,0,2,2],\n",
    "                        [2,0,0,0,1]\n",
    "                       ]]])\n",
    "out = kernel(input)\n",
    "out.shape, out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ConvMixer\n",
    "\n",
    "![image-20221114225059224](https://tva1.sinaimg.cn/large/008vxvgGgy1h851m7os85j31om0huq7j.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "参数量统计：\n",
      "81\n",
      "3\n",
      "--------------------\n",
      "27\n",
      "3\n",
      "9\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# 常规卷积参数量：84， 分开后：42\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "conv_general = nn.Conv2d(3,3, 3, padding='same')  # 常规卷积\n",
    "\n",
    "# ConvMixer\n",
    "subconv_space_mixing = nn.Conv2d(3,3,3, groups=3, padding='same')  # 空间融合\n",
    "subconv_channel_mixing = nn.Conv2d(3,3,1)  # point-wise卷积，通道融合\n",
    "print(f'参数量统计：')\n",
    "for p in conv_general.parameters():\n",
    "    print(torch.numel(p))\n",
    "print(f'-'*20)\n",
    "for p in subconv_space_mixing.parameters():\n",
    "    print(torch.numel(p))\n",
    "for p in subconv_channel_mixing.parameters():\n",
    "    print(torch.numel(p))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
